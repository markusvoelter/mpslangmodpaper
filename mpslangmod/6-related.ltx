
\section{Related Work}
\label{Related} 

\subsection{Projectional}

MPS is not the only projectional workbench and projectional workbenches are not
the only approach to language modularity and composition. For example, the
Intentional Domain Workbench (IDW) \cite{SimonyiCC06} is another projectional
editor that has been used in real projects. An impressive presentation about its
capabilities can be found in an InfoQ presentation titled "Domain Expert DSL"
(\ic{http://bit.ly/10BsWa}). IDW is conceptually very similar to MPS, although
quite different in many details. 

\label{cedalion} 
Cedalion \cite{cedalion} is a host language for defining internal DSLs. It uses
a projectional editor and semantics based on logic programming. Both Cedalion and
language workbenches such as MPS aim at combining the best of both worlds from
internal DSLs (combination and extension of languages, integration with a host
language) and external DSLs (static validation, IDE support, flexible syntax).
Cedalion starts out from internal DSLs and adds static validation and
projectional editing, the latter avoiding ambiguities resulting from combined
syntaxes. Language workbenches start from external DSLs and add modularization,
and, as a consequence of implementing base languages with the same tool,
optional tight integration with general purpose host languages. We could not
have used Cedalion as the platform for mbeddr tough, since we implemented our
own base language (C), and the logic-based semantics would not have been a good
fit.


\subsection{Parser-Based}





Eclipse Xtext (\ic{http://eclipse.org/Xtext}) supports the creation of extremely
powerful text editors (with code completion, error checking and syntax coloring)
from an enhanced EBNF-like grammar definition. It also generates a meta-model
that represents the abstract syntax of the grammar as well as a parser that
parses sentences of the language and builds an instance of the meta-model. Since
it uses the Eclipse Modeling Framework (EMF) as the basis for its meta models,
it can be used together with any EMF-based model transformation and code
generation tool (examples include Xpand, ATL, and Acceleo, all at
\ic{http://eclipse.org/modeling}). Language referencing is easily possible: code
completion for references into other models as well as cross-model and
cross-language consistency checks in the editor are supported natively. Just
like with any other reference, scopes may have to be defined manually. Language
reuse, extension and embedding are quite limited, though. It is possible to make
a language extend \emph{one} other language. Concepts from the base language can
be used in the sub language and it is possible to redefine grammar rules defined
in the base language. Creating new subtypes (in terms of the meta-model) of
language elements in the base language is also possible. However, it is not
possible to embed arbitrary languages or language modules. This is mainly
because the underlying parser technology is antlr \todo{ref to paper!} which is
a classical two phase LL(*) parser which has problems with grammar composition
\cite{BravenboerV08}. 

Monticore (\ic{http://monticore.org}) is another parser-based language
engineering environment that generates parsers, meta-models, and editors based
on extended grammar. Currently, the group at RWTH Aachen university works on
modularizing languages \cite{KrahnRV10}. Languages can extend each other and can
be embedded within each other. An important idea is the ability to not
regenerate the parsers or any of the related tools after a combined language has
been defined.

A particularly interesting comparison can be made with the Helvetia system by
Renggli et al. \cite{2010_renggli_embedding_languages_without_breaking_tools}.
It supports language embedding and extension of Smalltalk using
\emph{homogeneous} extension, which means that the host language (Smalltalk) is
also used for \emph{defining} the extensions (in contrast to some of the
embedded DSLs discussed above, Helvetia can work with custom grammars for the
DSLs). The authors argue that the approach is independent of the host language
and could be used with other host languages as well. While this is true in
principle, the implementation strategy heavily relies on some aspects of the
Smalltalk system that are not present for other languages, and in particular,
not in C. Also, since extensions are defined in the host language, the complete
implementation would have to be redone if the approach were used with another
language. This is particularly true for IDE support, where the Smalltalk IDE is
extended using this IDE's APIs. mbeddr uses a \emph{heterogeneous} approach
which does not have these limitations: MPS provides a language-agnostic
framework for language and IDE extension that can be used with any language,
once the language is implemented in MPS.
  
In the same paper, Renggli and his colleagues introduce three different flavors
of language extension. A \emph{pidgin} creatively bends the existing syntax of
the host language to to extend its semantics. A \emph{creole} introduces
completely new syntax and custom transformations back to the host language. An
\emph{argot} reinterprets the semantics of valid host language code. In
terms of this classification, bith extension and embedding are creoles. 


Several works avoid these limitations by making language definition and
extension first class. Early examples include the Synthesizer
Generator~\cite{RepsT84} as well as the Meta Environment~\cite{Klint93}. Both
generate editors and other IDE aspects from a language definition. The topic is
still actively researched. For example, Bravenboer et al.
\cite{2004_bravenboer_concrete_syntax_for_objects} and Dinkelacker
\cite{2011_dinkelaker_incremental_concrete_syntax_for_embedded_languages} 
provide custom concrete syntax, Bracha \cite{2004_bracha_pluggable_type_systems}
provides pluggable type systems and Erweg et al.
\cite{2011_erdweg_growing_a_language_environment} discuss modular IDE
extensions. Eisenberg and Kiczales propose explicit
programming~\cite{EisenbergK07} which supports semantic extension as well as
editing extensions (concrete syntax) for a given base language. 

Our approach is similar in that we provide extensions of syntax, type systems,
semantics and IDE support for a base language. mbeddr is different in that it
extends C, in that we use a projectional editor and in that we address IDE
extension including advanced features such as type systems, refactorings and the
debugger. The use of a projectional editor is especially significant, since this
enables the use of non-textual notations and annotation of cross-cutting meta
data.



Note that while parser-based approach are becoming more flexible (as illustrated
by some of the tools mentioned in this section), they will not be able to
work with non-parseable code, inlined tables, diagrams or annotations. 

For a general overview of language workbenches, please refer to the Language
Workbench Competition at \ic{http://languageworkbenches.net}. Participating
tools have to implement a standardized language and document the implementation
strategy. This serves as a good tutorial of the tool and makes them comparable. 
As of June 2012, the site contains 15 submissions.


\subsection{Other}



FURCAS (\ic{http://www.furcas.org/}) is a tool that is developed by SAP and FZI
Karlsruhe. FURCAS stores models in an abstract structure. However, for editing
it "projects" the model into plain ASCII. So when editing the model, users
actually edit ASCII text. Consequently, syntax definition also includes a
definition of indentation and white space conventions, otherwise the projection
could not work. Second, a lot of effort has to be put into retaining object
identity \cite{Goldschmidt08}. If an abstract structure is projected into text,
and then something is moved around and saved back into the abstract structure,
it has to be made sure the objects (identified by UUIDs) are not deleted and
recreated, but really just moved. This is important to make sure that references
between models which are based on the UUIDs and not (qualified) names remain
valid. By using scannerless parsers it is possible to combine different
languages, however a combined grammar has to be defined and the parser has to be
regenerated to be able to use the composed language. As a consequence of the
projectional approach, it is possible to define several syntaxes for the same
abstract structure or define views and subsets for a model. FURCAS also
generates IDE-like editors (based on Eclipse).


\subsection{Languages + IDE}

\todo{For all of those tools discuss syntax, type sys and semantics. And maybe
remove one or two of them since I'll add all the other related work below? }

\todo{comapre to parser-based stuff in general - references: spoofax stuff: you
need espace syntax to embed languages, and you have to define the ``composed
lang'' explicitly.}


 



SDF \cite{HeeringHKR89} (\ic{http://strategoxt.org/Sdf}), developed by the
University of Amsterdam, uses scannerless parsers. Consequently, languages can
be embedded within each other. However syntactic escapes (quotations and
antiquotations) have to be defined in the adapter language. This is not
necessary in MPS, which leads to a smoother integration among languages. 
Several IDEs have been developed for SDF and the languages defined with it. The
first one was the Meta Environment \todoref{}. More recent ones include Rascal
\todoref{} and Spoofax \cite{KatsV10}. The latter two both provide Eclipse-based
IDE support for languages defined via SDF. In both cases the IDE support for the
composed languages is still limited (for example, at the time of this writing,
Spoofax only provides syntax highlighting for an embedded language, but no code
completion), but will be coming. Spoofax uses the Stratego \todoref{} term
rewriting engine for expressing transformations. Spoofax also uses term
rewriting for expressing typing rules (a rule \ic{type-of} rewrites an AST term
to its type term), so type systems are modular and extensible as well.
\todo{More details on Rascal's language composition?}
\todo{More details on MetaEnv?}

\todo{cite some more of eelco's work? Like the SQL-in-Java thing?}

















\subsection{Language Only}


The contribution of this paper is the systematic definition and classification
of language modularization approaches, as well as the challenges and solution
involved regarding syntax definition, type systems, transformations and IDE
support. The idea of language modularization and composition itself is not new,
however. 

We already discussed the language modularization and composition approaches
proposed by Mernik et. al. \cite{MernikHS05} in \sect{classification}. 

 
\phead{Incremental Extension of Languages} was first popularized in
the context of Lisp, where definition of language extensions to solve problems
in a given domain is a well-known approach. Guy Steele's Growing a Language
keynote explains the idea well \cite{Steele99}. The paper on Xoc
\cite{CoxBCKK08} describes the idea of extending C incrementally, albeit without
extending a corresponding IDE. Sergey Dmitriev discusses the idea of language
and IDE extension in his article on Language Oriented Programming
\cite{lopnextprogrammingparadigm}, which uses MPS as the tool to achieve the
goal.

\phead{Macro Systems} support the definition of additional syntax for
existing languages. Macro expansion maps the new syntax to valid code in the
extended language, and this mapping is expressed with host language code instead
of a separate transformation language.They differ with regard to degree of
freedom they provide for the extension syntax, and whether they support
extensions of type systems and IDEs. The most primitive macro system is the C
preprocessor which performs pure text replacement during macro expansion. The
Lisp macro system is more powerful because it is aware of the syntactic
structure of Lisp code. An example of a macro system with limited syntactic
freedom is the The Java Syntactic Extender \cite{504285} where all macros have
to begin with names, and a limited set of syntactic shapes is supported. In
OpenJava \cite{TatsuboriCIK99}, the locations where macros can be added is
limited. More fine-grained extensions, such as adding a new operator, are not
possible.

% Our work relates to macro systems such as Open Java~\cite{TatsuboriCIK99}in that
% mbeddr customizes the translation of language extensions.
% However, mbeddr uses non-local transformations as well; those are not easily
% expressible with macros. Also, traditionally, macros have not addressed IDE
% extension.


\phead{Language Cascading} refers to a form of language combination where a
program expressed in languge $l_1$ is translated into a program expressed in
language $l_2$. Essentially this is what every code generator or compiler does;
the languages themselves are not related in any way except through the
transformation engine, which is why we don't consider this as an example of
language modularization and composition. An example of this approach is KHEPERA
\cite{FaithNP97}

\phead{Full Language Extension and Composition} refers to the case where
arbitrary syntax can be added to a host language, and type systems and IDEs are
aware of the extension. This paper classifies four approaches for doing this.
Existing implementations exist. For example, Bravenboer and Visser describe how
SQL can be embedded into Java to prevent SQL injection attacks
\cite{BravenboerDV07}. The same authors discuss library-based language extension
and embedding in \cite{BravenboerV07}. A more recent publication
\cite{Erdweg-OOPSLA-2011} also based on SDF introduces SugarJ, which supports
library based languages extension. \cite{Erdweg-GPCE-2011} adds IDE support.

Open compilers such as Jastadd~\cite{EkmanH07} are related in that 
they support language extension and custom transformation. However, while
open compilers can typically be extended with independent modules, the input
language often requires invasive adaptation. Also, open compilers do not address
IDE extension. 

\phead{Internal DSLs} are languages embedded in general purpose host
languages. Suitable host languages are those that provide a flexible syntax, as
well as meta programming facilities to support the definition of new
abstractions with a custom concrete syntax. For example \cite{HoferORM08}
describes embedding DSLs in Scala. In this paper we don't address internal DSLs,
because IDE support for the embedded languages is not available in these cases,
and we consider IDE support for the composed languages essential.
The landmark work of Hudak~\cite{1998_hudak_modular_dsl_and_tools} introduces
embedded DSLs as language extensions of Haskell. While Haskell provides advanced
concepts that enable such extensions, the new DSLs are essentially just
libraries built with the host language and are not first class language
entities: they do not define their own syntax, compiler errors are expressed in
terms of the host language, no custom semantic analyses are supported and no
specific IDE-support is provided. Essentially all internal DSLs expressed with
dynamic languages such as Ruby or Groovy, but also those embedded
in static languages such as Scala suffer from these limitations. 


\todo{More work on Semantic Extensibility}

\todo{(e.g., AbleJ, LISA, Modular denotational semantics, 
  Polyglot, Tattoo, ...) }
